#  ===== S3 ================= 

- https://www.udemy.com/course/aws-data-analytics/learn/lecture/14145463#overview

- infinitely scaling storage

use cases:
- storage
- backup & disaster recovery
- application hosting & media files (images)
- data lake + data analytics


# S3 buckets
- Where object files are stored. 
- names of bucket are globally unique
  but the bucket itself is created in a specific region

# Objects have a key 
The key is the full path:
```
eg.
s3://my-bucket/my_file.txt

eg.
s3://my-bucket/folder1/folder2/my_file.txt


PREFIX in [], OBJECT_NAME in <>:
[PREDIX]<OBJECT_NAME>
[s3://my-bucket/folder1/folder2/]<my_file.txt>
```

# Object max size
Maximum permitted size of an object is 5TB 
Uploading an object more than 5GB requires "multi-part upload"


# Objectcs can have metedata attached via TAGs
- You define the tags
- useful tag suggestions:
  a) version ID
  b) 


# ===== SECURITY ====================

# S3 security
1) IAM policies - placed on specific users
2) Resource-based policies:
   a) bucket policies
   b) object access controlled list
   c) bucket access controlled list
3) Encryption
   optional: objects can be encrypted and only accessed via encryption keys 


# Accessing S3 via an EC2 instance
1. Use IAM ROLES ... not IAM user policy
2. create an EC2 instance role with correct IAM role
   which allows ec2 to access s3

# ===== VERSIONING ====================

You can set your bucket so that version = enabled

1. First time you upload a file <file.txt> 
   It is version 1
2. If versioning is enabled at bucket level
   when you overwrite that file via a new upload
   of the same name, the version will update to 2 etc...

It is best practice to version buckets - to protect against accidental deletions...
... and we can restore previous versions of files if needed. 



# ======= Replication ===================

We can replicate or copy s3-bucket A to create replicated s3-bucket B ... via "asynchronous replication"

Replication can be:
1. Same-region replication
   eg. for replicating data from dev & test environments
2. Cross-region replication.
   eg. from region 1 to region 2. 
   eg. for compliance reasons, 
       or if region 2 offers lower latency for apps.


How? 
1 - enable versioning in source and destination buckets
2 - give proper IAM to s3 services 
    so we can read/write


# ======= S3 storage classes ===================

1. S3 - standard - for general purpose storage
2. S3 standard-infrequent access
3. S3 one zone-infrequent access
4. S3 glacier instant retrieval
5. S3 glacier flexible retrieval
6. S3 glacier deep archive
7. S3 intelligent tiering


Durability:
how many times an objects will be lost by S3. 
On average, 
if you store 10 million objects on S3, 
you can expect to lose 1 object
once every 10,000 years. 
Durability is same across all S3 tiers. 

Availability:
measures how readily available service is
On average, for 53 minutes a year, S3 will not be available. 

### S3 general purpose
- for frequently accessed data
- low latency & high through put
- use for big data

### S3 infrequent access (objects not accessed for ~30 days)
- lower cost of storage
- higher cost for retrieval

### S3 glacier (objects not accessedf over 90 days-700+)
- lowest storage
- highest and slowest retrival cost
- enforces "minimum storage durations"
- use for data back-up

### S3 intelligent tiering
- small monthly fee for monitoring 
- can move obects between different S3 tiers..
  based on usage



